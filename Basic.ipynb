{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from helper_funcs import * \n",
    "\n",
    "import pandas as pd \n",
    "# prop = fm.FontProperties(fname='kalpurush ANSI.ttf')\n",
    "# matplotlib.rcParams['font.family'] = prop.get_name()\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "from numpy import linalg as LA\n",
    "\n",
    "batch_size=128\n",
    "random_state = 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(testloader, net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "            \n",
    "    acc = 100 * correct / total\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_accuracies(net):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels.to(device)).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_errors(testloader, net, n=10):\n",
    "    count = 0\n",
    "    ims = []\n",
    "    preds = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)            \n",
    "            \n",
    "            for (im, pred, label) in zip(images, predicted, labels):\n",
    "                if pred.numpy() != label.numpy():\n",
    "                    count += 1\n",
    "                    ims.append(im.numpy())\n",
    "                    preds.append(pred)\n",
    "                    actual.append(label)\n",
    "                    \n",
    "                if count >= n: \n",
    "                    return ims, preds, actual \n",
    "                \n",
    "    plot_gallery2(ims, preds, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = BengaliDataset(\"data/train.csv\",\"data/trainsplit\", transform)\n",
    "testset = BengaliDataset(\"data/test.csv\",\"data/testsplit\", transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "classes = list(range(df.label.max()+1))\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels,t = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "plot_gallery2(images,labels,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our simple 2FC model:  \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32*13*13, 100)\n",
    "        self.fc2 = nn.Linear(100, n_classes)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "        self.last_hidden = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32*13*13)\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def get_last_hidden(self,x):\n",
    "        x = self.pool(self.ReLU(self.conv(x)))\n",
    "        x = x.view(-1, 32*13*13)\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        return x \n",
    "    \n",
    "net = Net().to(device)\n",
    "output = net(images.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1292])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.358 \t accuracy: 0.112\n",
      "[1,   200] loss: 0.716 \t accuracy: 0.106\n",
      "[1,   300] loss: 1.074 \t accuracy: 0.174\n",
      "[1,   400] loss: 1.432 \t accuracy: 0.148\n"
     ]
    }
   ],
   "source": [
    "# Training with MSE/Quadratic loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels, _ = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.to(device))        \n",
    "        loss = criterion(outputs.to(device), labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 100 == 0:    # print every 2000 mini-batches\n",
    "            test_acc = get_accuracy(testloader, net)\n",
    "\n",
    "            print('[%d, %5d] loss: %.3f \\t accuracy: %.3f' % (epoch + 1, i + 1, running_loss / 2000, test_acc))\n",
    "                        \n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on test images: 7 %\n"
     ]
    }
   ],
   "source": [
    "# CrossEntropyLoss model \n",
    "print_accuracy(testloader, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    images, labels, _ = next(iter(testloader))\n",
    "    outputs = net(images.to(device))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
