{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from helper_funcs import * \n",
    "\n",
    "import pandas as pd \n",
    "# prop = fm.FontProperties(fname='kalpurush ANSI.ttf')\n",
    "# matplotlib.rcParams['font.family'] = prop.get_name()\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "from numpy import linalg as LA\n",
    "\n",
    "batch_size=128\n",
    "random_state = 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(testloader, net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_accuracies(net):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels.to(device)).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_errors(testloader, net, n=10):\n",
    "    count = 0\n",
    "    ims = []\n",
    "    preds = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)            \n",
    "            \n",
    "            for (im, pred, label) in zip(images, predicted, labels):\n",
    "                if pred.numpy() != label.numpy():\n",
    "                    count += 1\n",
    "                    ims.append(im.numpy())\n",
    "                    preds.append(pred)\n",
    "                    actual.append(label)\n",
    "                    \n",
    "                if count >= n: \n",
    "                    return ims, preds, actual \n",
    "                \n",
    "    plot_gallery2(ims, preds, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = BengaliDataset(\"data/train.csv\",\"data/trainsplit\", transform)\n",
    "testset = BengaliDataset(\"data/test.csv\",\"data/testsplit\", transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "classes = list(range(df.label.max()+1))\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels,t = next(iter(trainloader))\n",
    "# images, labels,t = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "plot_gallery2(images,labels,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32*13*13, 100)\n",
    "        self.fc2 = nn.Linear(100, n_classes)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "        self.last_hidden = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32*13*13)\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def get_last_hidden(self,x):\n",
    "        x = self.pool(self.ReLU(self.conv(x)))\n",
    "        x = x.view(-1, 32*13*13)\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        return x \n",
    "    \n",
    "net = Net().to(device)\n",
    "output = net(images.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1292])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.004\n",
      "[1,  1001] loss: 3.582\n",
      "[2,     1] loss: 0.004\n",
      "[2,  1001] loss: 3.582\n",
      "[3,     1] loss: 0.004\n",
      "[3,  1001] loss: 3.580\n",
      "[4,     1] loss: 0.004\n",
      "[4,  1001] loss: 3.579\n",
      "[5,     1] loss: 0.004\n",
      "[5,  1001] loss: 3.576\n",
      "[6,     1] loss: 0.004\n",
      "[6,  1001] loss: 3.573\n",
      "[7,     1] loss: 0.004\n",
      "[7,  1001] loss: 3.568\n",
      "[8,     1] loss: 0.004\n",
      "[8,  1001] loss: 3.560\n",
      "[9,     1] loss: 0.004\n",
      "[9,  1001] loss: 3.544\n",
      "[10,     1] loss: 0.004\n",
      "[10,  1001] loss: 3.513\n",
      "[11,     1] loss: 0.004\n",
      "[11,  1001] loss: 3.455\n",
      "[12,     1] loss: 0.003\n",
      "[12,  1001] loss: 3.354\n",
      "[13,     1] loss: 0.003\n",
      "[13,  1001] loss: 3.211\n",
      "[14,     1] loss: 0.003\n",
      "[14,  1001] loss: 3.072\n",
      "[15,     1] loss: 0.003\n",
      "[15,  1001] loss: 2.949\n",
      "[16,     1] loss: 0.003\n",
      "[16,  1001] loss: 2.845\n",
      "[17,     1] loss: 0.003\n",
      "[17,  1001] loss: 2.757\n",
      "[18,     1] loss: 0.003\n",
      "[18,  1001] loss: 2.683\n",
      "[19,     1] loss: 0.002\n",
      "[19,  1001] loss: 2.617\n",
      "[20,     1] loss: 0.003\n",
      "[20,  1001] loss: 2.560\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training with MSE/Quadratic loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels, _ = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.to(device))        \n",
    "        loss = criterion(outputs.to(device), labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on test images: 7 %\n"
     ]
    }
   ],
   "source": [
    "# CrossEntropyLoss model \n",
    "print_accuracy(testloader, net)\n",
    "\n",
    "# Get 10 test set errors \n",
    "# im, p, l = show_errors(testloader, net, n=10)\n",
    "# plot_gallery2(im, p, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    images, labels, _ = next(iter(testloader))\n",
    "    outputs = net(images.to(device))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vowel_diacritic.max(), df.consonant_diacritic.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
