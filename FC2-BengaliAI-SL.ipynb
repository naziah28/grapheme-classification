{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from helper_funcs import * \n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd \n",
    "# prop = fm.FontProperties(fname='kalpurush ANSI.ttf')\n",
    "# matplotlib.rcParams['font.family'] = prop.get_name()\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "from numpy import linalg as LA\n",
    "\n",
    "import tensorboardX\n",
    "\n",
    "batch_size=128\n",
    "random_state = 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "tb_writer = tensorboardX.SummaryWriter('storage/2fc-sl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/label-mappings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>771</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  grapheme_root  vowel_diacritic  consonant_diacritic  label\n",
       "771         771            102                0                    0    771"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label == 771]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(testloader, net, batch=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "            \n",
    "            gt = 0 \n",
    "            vt = 0 \n",
    "            ct = 0 \n",
    "            \n",
    "            if batch: \n",
    "                overall = 100 * correct / total\n",
    "                \n",
    "                for (pred, label) in zip(predicted, labels):                    \n",
    "                    l = label.item()\n",
    "                    p = pred.item()\n",
    "                    g, v, c = df[df.label == l].grapheme_root.values[0], \\\n",
    "                        df[df.label == l].vowel_diacritic.values[0], \\\n",
    "                        df[df.label == l].consonant_diacritic.values[0]\n",
    "                    \n",
    "                    pg, pv, pc = df[df.label == p].grapheme_root.values[0], \\\n",
    "                        df[df.label == p].vowel_diacritic.values[0], \\\n",
    "                        df[df.label == p].consonant_diacritic.values[0]   \n",
    "                    \n",
    "                    if g == pg: \n",
    "                        gt += 1 \n",
    "                    if v == pv: \n",
    "                        vt += 1\n",
    "                    if c == pc: \n",
    "                        ct+=1 \n",
    "                g_acc = 100*gt/batch_size\n",
    "                v_acc = 100*vt/batch_size\n",
    "                c_acc = 100*ct/batch_size\n",
    "                overall = (g_acc*2 + v_acc + c_acc) /4 \n",
    "                \n",
    "                return g_acc, v_acc, c_acc, overall\n",
    "                \n",
    "    overall = 100 * correct / total\n",
    "    \n",
    "    return overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = BengaliDataset(\"data/train.csv\",\"data/trainsplit\", transform)\n",
    "testset = BengaliDataset(\"data/test.csv\",\"data/testsplit\", transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "classes = list(range(df.label.max()+1))\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels,t = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAACQCAYAAACLf1ggAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAaM0lEQVR4nO3deZgV1ZnH8d9hURAQFaRxR4wgRmVxjYq4YRxGxZERt0iGiDBP1Hl0zMioMZpHXGI0mqiIxj3oqPFBY1TcFRJxF0RQFBcQZLOBZhEQ1DN/VHVb79tbddPLbfr7eZ5+uL+u2/fW7Xu67qHOW+eEGKMAAACq06KxdwAAADQNdBoAAEAudBoAAEAudBoAAEAudBoAAEAudBoAAEAudBpyCiHsGUJ4u44e6w8hhP+si8dCw6nLNlDN8xSFED4MIWxe38+F2qM9wGsObaLgOg0hhDkhhKMbez8qcKWk6yUphLB5COGuEMLcEMKqEMLUEMK/lN6xtOGEEJanXy+EEPbMPNbvJV0aQtisgV9Dk9AU2oAkhRBeCSGsCyGsTr8+ymw7IoTwfgihJISwNITwWAhhh8z2oSGEKSGENSGEV7JPEmNcLOllSSPr/yUVvqbSHiQphHBqejD/OoTwaQihf2bbFiGEsSGE4hDCihDC5My2EEL4XdpWloYQrgshBIn2UJGm0Caq+5zICiFcHkKI2dcUQtghhPC3EMKyEML87H80G7NNFFynodCEEFqFELaTdISkx9Nvt5I0T9IASR0lXSbpkRBCt3T7Akn/LmkbSZ0lPSHpodLHjDEulDRL0gn1/wqwsSppA6XOjTG2T796Zr7/gaSfxhi3krS9pNmSbstsXybpJknXVvK0D0gaVScvAHWqsvYQQhgo6XeShkvqIOkwSZ9lfvQOJceEXum/F2S2jZR0oqTekvaRdJzs+097KGC1/Jwo/dndlHxeLHQPO17S55KKJP2rpKtDCEdktjdOm4gxFsyXpL9I+l7SWkmrJV0k6SBJUySVSHpP0uGZ+7+ipGf3qqRVkp6T1Dnd1kbJL31p+rNvSSpKt22v5IN8maRPJJ2decwrJD2a/uxKSSMkDZP0QjX7Pl3SkAq+30rSOZLWuO9fKumexv6dF9pXU2oD6XOPyPGaNpd0jaQPKtg2QtIrlbSbNZJ2aez3hPaQuz1MkXRWJa+jZ/qzW1ayfYqkkZl8lqTXaQ9Nu01UsO/lPickTZQ0SNIcSUen32svKUraNnO/OyT9pbHbRKM3gAp+qdlf3A7pmzlIyVmRgWneNtMYPpXUQ1LbNF+bbhsl6e+StpDUUtK+pX+wkiZJGps2mD6SvpJ0VKYxbFDS62+RPu7vJd1axT4XSVonaQ/3/RJJ36YN/Ndu20mS3m3s33chfjWVNpA+11eSipUckA5323dO28D36eP9RwWvtcJOQ7ptuqQTGvv9aOyvptAe0sdbL+l/lXzAzJd0i6S26fZhkt6XdGPaXt5X5sND0gpJB2byfpJW0R6abpuoYJ/LfU5IOlnS3yp4TR2UdBq6ZO77Z0lTG7tNFPrwxM8kPR1jfDrG+H2M8XlJbytpHKXuiTF+HGNcK+kRJW+ulLyhnST9KMb4XYzxnRjjyhDCTpIOlTQ6xrguxjhN0p2Szsw85msxxsfT51wraSslPdRyQgitlZwmui/GOCu7LSanpjtKOlfSVPejq9LHRdUKuQ2MltRdyUHrDkl/T081SpJijF+kbaCzpF8rGZKqCdpIeYXaHooktVZymrl/+px9lbzvkrSjpL2UdA62V3JMuC+E0Cvd3j7dVmqFpPaldQ0p2kPFCrVNlKnocyKE0F7S1ZLO9/ePMa5S8h+Ry0IIbUII/SQNUdK5yWrwNlHonYZdJJ2cFpOVhBBKlLyR22Xusyhze42SPz4pOYX1rKSHQggL0sKi1kr+YJelb0qpuUoO/KXmuf1YrqTnZ4QQWqTPs17JQaCcGOPXksZJuj+E0CWzqYOS/4WiagXbBmKMb8QYV8UYv4kx3qfkj3yQ+znFGJdJuk/S30IIrfK9bEm0kYoUantYm/57c4xxYYyxWNIf9EN7WKvkA2pMjHF9jHGSkkK2Y9LtqyVtmXm8LSWtjul/J1O0h4oVapuQVOXnxG+VDDd8XsnrOkPSrunz3Kak0zHf3afB20QhdhqyfyTzlPxSt8p8tYsxVlY89sODxLghxvjbGOOekg5WUlg0TEmR4jYhhOybu7OkLyvZByk5BdQj+430fwB3KfkfxpAY44YqdqeFkh5itsH1UjL2hvKaRBuoZL9DJdtaSeoi+8FQqbRz8SPRRqQm0B5ijMuVHNArWzZ4ejW7N1NJEWSp3un3JNEeKlDwbUKq9nPiKEn/FUJYFEJYJGknJYWSo9N9mxtjPC7GuG2M8UAlZ0TezDx2o7SJQuw0LFZyyldKikyODyH8NITQMj1Nc3gIYcfqHiS95G3vEEJLJYUqGyR9F2Ocp6Rg5pr08fZRUnT0QBUP97ykfiGENpnv3abkg//49NRU9rkHhhD6pvu8pZL/cSyX9GHmbgOUFMCgvIJvAyGErdJ9apNWTp+hpFr+2XT7SSGEniGEFiGEbZW0ganpWQeVvhYlnYkW6eO0zjzfAZLmxBjn5vuVbdIKvj2k7pF0XgihSwhhayWnnZ9Mt02W9IWki9P2coikw5W2F0n3S/rvkFxmt72kCyXdm3ls2oPVVNpEpZ8TSjoNeykZKumjpKMyStKt6b71CiF0CCFsFkL4mZKzUn/I/HyjtIlC7DRcI+nX6SmmUyQNlnSJkiKUeZL+R/n2u6uS6taVSj6sJylpXJJ0mqRuSt6kxyRdno6DVSgm18S+lO6LQgi7KHlz+0haFH64Tv+M9Ee2kvR/SsYlP1XSGzw2xrgu/fntJO2p8pfvIVHwbUDJ+PUY/VAIeZ6kE2OMpXM17CDpGSVjju8rKYb8t8xDnqnklPVtSsbA1yopdCp1hpJhLTSN9iAlFfpvSfo4ffypkq5K778hve8gJceFP0salqmDul1JQd77kmZIeir9Xinag1XwbaK6z4kY49IY46LSL0nfSVoeY1ydPuRPlVyyu1zSfyr5DPkq85SN0iaCHTJDZUIyOdN9kg6IG/lLCyHcIOnTGOPYOtk5NIi6bAPVPE8XJQevvqUdTRQe2gO85tAm6DQAAIBcCnF4AgAAFCA6DQAAIBc6DQAAIBc6DQAAIJeazE6nEAJVk01UjLGySYdqjfbQpBXHGLet6welTTRdHCPgVHiM4EwD0DwxSRCAqlR4jKDTAAAAcqHTAAAAcqHTAAAAcqHTAAAAcqHTAAAAcqnRJZcA6kfr1q1N3mGHHUxesmSJyWvWrKn3fQIAjzMNAAAgFzoNAAAgFzoNAAAgF2oagEbQvn17k88880yTR44cafLw4cNNnjZtWv3sGABUgTMNAAAgFzoNAAAgFzoNAAAgF2oagDrQooXtf3fq1MnkQw891OSTTz7Z5N69e5t8yy23mDxr1qyN3UUATUgIVa9UHmPjrDrOmQYAAJALnQYAAJALnQYAAJALNQ1ALXTt2tXkESNGmDxkyBCTW7Wyf2ovvPCCyX4ehqlTp5q8YcOGWu0ngMLg657atWtnco8ePUw+8sgjTS4uLjZ5woQJJq9YsWJjdzEXzjQAAIBc6DQAAIBc6DQAAIBcqGkAcmjTpo3JY8aMMfmss84y+f777zf5xhtvNPmDDz4wef369Ru7i6hAy5YtTfbXtn///fcNuTvYhPh5FDbffHOT99xzT5MPO+wwk/faay+Ti4qKTN5ss81M/vrrr01et26dyRMnTjS5pKSkot3eaJxpAAAAudBpAAAAudBpAAAAuVDTAOTgaxp23XVXkydNmmTy+eefb/Ly5cvrZ8eaOT+O7Nf48Ne6L1myxGR/rbvfXt38/zXhr8v3+7548WKTfb1FY6010Jz59799+/Zlt/fdd1+z7dhjjzW5e/fuJi9cuNBkX4Mwc+ZMkxctWmTylltuWem+SNK3336rhsCZBgAAkAudBgAAkAudBgAAkAs1DbXUsWNHk/0Yd+fOnU32Y9pffPGFyUuXLq3y+bievHGtXLnS5GnTppn84x//2ORtt93WZD8vPO9nPn6+/p133tnks88+2+SRI0ea7Odp+O6770w+9dRTTX733XdN/uabb8pu+/U//BiyX1/EP5dvI35M+plnnjHZ11f4Y8iCBQtM/vLLL6v8eb8/KK9169Ym9+7d2+Qzzjij7HanTp3MtilTpph85513mjx//nyTs21Lqr5mpb7mXagpzjQAAIBc6DQAAIBc6DQAAIBcmlRNg5+Lu23btib7a2r9mFFVY0i+JsHPC+7HqAcOHGiyH/NetmyZyf4a2w4dOpjsxyP9+Omf/vQnk7/66iuh4fgahFtvvdVkPz9At27dTPbjmWvWrKm7nduE9evXz+Rx48aZvNVWW5l8xx13mDxr1iyT/ft41FFHmfz444+bnP078/URnl8bwM/tcdFFF5nsj1czZsyo9Lml8jUQ/hjij2G+jfm6GpSvYRgyZIjJgwYNMvnll18uu/3aa6+Zbb7mxH/e+OfyNTCer3GorqamoeqkONMAAAByodMAAAByodMAAAByKaiaBl+j0L9/f5MPOeQQk7t06WKyH+Px17UWFxebnB1z+uUvf2m2bb311ib7sdP169ebfO2115p89913m+zHF/3443nnnWfy8OHDTfbXcFPT0Lg+++wzkz///PMq78+6AbXj12vwf4fjx483+frrrze5ujqDN954w+RPP/3U5J49e5bd9scIX1Mwffp0k309hc9+bYFVq1aZ/Pbbbws1s80225hc3foeBxxwgMkHHnigyTfddFOlj3/zzTebbX7ehk8++cTk2bNnm+xrFHz2nxlr1641efLkySZ/8MEHagicaQAAALnQaQAAALnQaQAAALk0ak2Dn3fBzwP/k5/8xOS//vWvJvsxIj+3uh/P2n333U2+/PLLy27vvffeZtuTTz5p8nPPPVflc/saBH+d/pgxY0z240833HCDyX6eiC222EKoX9nrqP01+b7exo+1d+3a1WQ/du7bor//jjvuaPLHH39s8hNPPGFyc1lHwNct/eMf/zDZz+/vaxh8LYkfF/Y1DP75suPWvp7Cz7vg52IZNWqUyQsXLjT50UcfNbmoqEioGT/XxRFHHGHySSedZPJjjz1msq8te/311032tWvnnntu2e2jjz7abMvO4SCV/5v1NSq+hsHz2/28Do1V18aZBgAAkAudBgAAkAudBgAAkEuD1jT48Sc/70KfPn1Mvu6660z244/VXfvun6979+4mZ+fq9tfZf/jhhyY/++yzJvsx5/fee8/k0aNHm3zFFVdUud1fs+3XovDzzqM8P7d7x44dTfbvv78mO9v+OnfubLb537+vefA1J3780ddA+Hniffvz1/w3l3kefJ3T4YcfbvILL7xgsv87qenvyd//sMMOM3n//fcvu33xxRebbf46ef+e+hqIkSNHmuzXJvBzCKB6/v178803Tfa1agMGDDDZ1yz4NYZ8+9ttt93Kbvu5eB555BGTfVvdVOqQONMAAAByodMAAAByodMAAAByadCaBn8d8zHHHGOyX8vez+9f0xqGvn37mnz66aebPHbs2LLb/ppqPy+Dr6fw/DXYfs7yu+66y2R/PfFTTz1lsl+b3V/nj/JzG1xyySUm+7VLfM3D3LlzTc6OQfuxzYcfftjkdevWmezXPfHzcPj5A+bMmWNydesQNJeaBl8H4OdNmDp1qskb+3vxtSl+DHvFihVltydOnGi2VTdGPWPGDJP93ByHHnqoya+++qrJ/njWXNrAxpg3b57J11xzjcn+GOD533m2hkGyNS4PPfSQ2TZp0iST/fu1qbyfnGkAAAC50GkAAAC5NOjwhJ8W008LPXPmTJP9JUxeixa2z3PwwQebPGLECJMffPBBk7OnkP3whD/1WN2pSH/q6aCDDjLZL9k6ePBgk/1wSHVL+qL8tOB++Mmfer7yyitN9kNC2Us0/fCSH67wl1v5oTQ/xeumcrlVffN/J34YyA/j1DW/HPGLL75Y6+f2Qy3+kt8//vGPJvtL9MaNG2eyn6aYNlU9f1mrz9VZunSpydnPsP32289s6927t8n+km9/ebA/5s+fP7/S55IKZziDMw0AACAXOg0AACAXOg0AACCXBq1p8OOF7777bo1+3tcNHHXUUSb7cehly5aZ3KNHD5MXLFhQdtuPnfrxyJryS2P7KbJ9vUaHDh1MXrlypcn+ctVN5fKdjeGn+vZTe/sxxX/+858mf/LJJyZXNa24v/TvnXfeMbmmY6WomJ+Oe/Xq1Sb7pa03lq8LuO+++0zOtgl/jKiOnxLb7/uECRNM9jVeQ4cONdlfxps9fqF++M+Q7FTf/rJ5f0z3xww/Fb2vwfLLvvvjU7a+RpK++OKLyna7XnGmAQAA5EKnAQAA5EKnAQAA5NKgNQ0ba9dddzX5ggsuMHn8+PEmT5s2zeQTTjih0nzAAQeYbX6K0Or4mgI/54SfZjo7Pa1U/ppcn/1YL6Sdd97ZZF/34a9z979DPzV3dupmP+/CiSeeWOVz+XkZ/Lwafv6BkpISk329T3Pl6wb8e9a2bVuTN7bGwc/10qtXL5N93UxNzJ4922R/fBozZozJfmlsP2a+0047mUxNQ/3z7TFbV+KX3T7//PNN9lNWH3vssSZXVxNxyimnmNyvXz+Tf/WrX5ncUHVVnGkAAAC50GkAAAC50GkAAAC5NKmaBr/88M0332zyK6+8YrIf75w8ebLJv/jFL8puDxw40GzzY6c15eeR//nPf26yn4fBL4XtXytLY5cff/ZLq/s6kQceeMBkX3dQ1dwWfil0P+eDX4uiqKjI5NGjR5vcs2dPk9944w2Tf/Ob35js20Nz4Wt/PL9+g7+Ovqb8OLKvKzjyyCPLbvu5O/z6MJ6/jt4v3e733R9z2rVrV+Xjo/75eTymT59ednvQoEFmmz+eFBcXm9ypUyeTfd2cPyb4uX0KZf0hzjQAAIBc6DQAAIBc6DQAAIBcmlRNgx8jrOnc234M8p577im77a+5bdmypck1XevB11M8//zzufdTKj/nfteuXU321wCvX7++Ro/fFPlr9g888ECTJ02aZPLSpUtNrsn6HH5s3Y83n3baaSafdNJJJn/00Ucm33777SZfffXVJj/99NMmT5w4Mfe+bkp8XYqvUzruuONM9vOhbOy8DX5Nkb59+5bdHjZsmNnm513IzvMhlf+b9GPcfm2K448/3uTOnTubPGfOnEr2Gg1lxowZZbf9XDoXXXSRyb4t+rlY5s2bZ/Kll15qsj/G33nnnSY31jGfMw0AACAXOg0AACAXOg0AACCXUJNx3hBC/js3Md26dTO5VStb7uHXNq9vZ511lsn+Gm9/jfDHH39ssn9fY4y2KKMONHR78GtNPProoyZffvnlJvu6AF+X4seUs2OUAwYMMNt8TYqfR+Ott94y+fTTT6/y/i+//LLJfuz+nHPOMdlfL14H3okx7lfXD1rXbcLPj+HHjf248L333muyXzugprJrhgwfPrzKx37iiSdM9msB7LjjjiYPHjzY5N69e5t82223mezboJ9jYmNtCseI+patdfNrR/Tv399kvzaI/0zx7//cuXNNvuGGG0z2dVI1+eyupQqPEZxpAAAAudBpAAAAudBpAAAAuTSpeRrqU6FdA+2v6V6yZInJfu2KBhjfanS+BsHPneDnZfDj4f46eL8eRHa9iWnTppltJSUlJvt5PK677jqT58+fX+W+f/jhhyb78Wz/2vy8Hc2Fn7dh3LhxJp933nkmn3nmmSY/8sgjVT5edbLrQ/i5NrLrUkjSiBEjTO7SpYvJfv2Y2bNnm+zrlmbNmmVyXdcwoOaytUUvvvii2ebn+Bg5cqTJQ4cONfnuu+822c/7UajHeM40AACAXOg0AACAXOg0AACAXJinoUD5a7r92hh+PK26ecg3hWuw/TwNTz31lMl+jDB7jb0k7bHHHib7upH27duX3b7sssvMNj92/t5775n88MMPm+yv0fdzRPjHHzVqlMn777+/yf6a7zrQJOZpqE5RUZHJp556qsl+vRI/14Ffv8bXxVQ1P4Z/T7Ptp6Ln9msR+LVw6mEujhrZFI4RDalNmzYmX3jhhSYffPDBJt94440mT5482eQCXD+IeRoAAEDt0WkAAAC50GkAAAC5ME9DgfLX+fvcHPnr1H3Ngl8b4MEHHzR57NixJg8bNszkKVOmlN32axpcfPHFJvu1JKq7ht7XDmXnhJCk1q1bm+xfWz3UNGwSFi9ebLJfr6FHjx4m77777ia3a9fO5LfffttkX3eQ5d/TVatWVZmxaenevbvJp5xyislXXXWVyS+99JLJTXXeDc40AACAXOg0AACAXOg0AACAXKhpQMFq0cL2aQcMGGCyvy7ejxkuWrTIZH+d9IQJE0x+4IEHym77a+br+hr6jz76qMrH79Wrl8kzZ840uVDmoS80/lr3GTNmmOx/jx6/V+Tl5/R4//33TR48eLDJy5cvN9m3Tb8uyoYNG0z2bdPXVTVU2+VMAwAAyIVOAwAAyIVOAwAAyIW1J5qJpjivvJ/b/dJLLzV5n332MblPnz4m+/Xon3zySZP9ddSrV6+u1X7WRseOHU0eP368yf61Dx061GQ/PloLm8TaE6g7TfEY0Zj82iM77bSTyccff7zJu+22m8m+/sbXNPiaiTlz5pjs165Yt25d1Ttcc6w9AQAAao9OAwAAyIVOAwAAyIWahmaiKY5X+jHD7bbbzmS/XoOf26C4uNhkf110PYwB1pofDy0qKjJ56tSpJtfBvBHUNMBoiseIQubnmWnbtq3Jft2TDh06mOyPfyUlJSb7mod6mKeBmgYAAFB7dBoAAEAudBoAAEAu1DQ0E4xXwqGmAQbHCDjUNAAAgNqj0wAAAHKh0wAAAHKh0wAAAHKh0wAAAHKh0wAAAHKh0wAAAHJpVcP7F0uaWx87gnq1Sz09Lu2h6aJNIIv2AK/CNlGjyZ0AAEDzxfAEAADIhU4DAADIhU4DAADIhU4DAADIhU4DAADIhU4DAADIhU4DAADIhU4DAADIhU4DAADI5f8BcxxRTM5Tf/kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "plot_gallery2(images,labels,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our simple 2FC model:  \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32*13*13, 100)\n",
    "        self.fc2 = nn.Linear(100, n_classes)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "        self.last_hidden = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32*13*13)\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def get_last_hidden(self,x):\n",
    "        x = self.pool(self.ReLU(self.conv(x)))\n",
    "        x = x.view(-1, 32*13*13)\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        return x \n",
    "    \n",
    "net = Net().to(device)\n",
    "output = net(images.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1292])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 7.170 \t test accuracy: 10.156\n",
      "[1,   200] loss: 7.159 \t test accuracy: 10.156\n",
      "[1,   300] loss: 7.162 \t test accuracy: 10.156\n",
      "[1,   400] loss: 7.163 \t test accuracy: 10.156\n",
      "[1,   500] loss: 7.176 \t test accuracy: 10.156\n",
      "[1,   600] loss: 7.170 \t test accuracy: 10.156\n",
      "[1,   700] loss: 7.184 \t test accuracy: 10.156\n",
      "[1,   800] loss: 7.165 \t test accuracy: 10.156\n",
      "[1,   900] loss: 7.170 \t test accuracy: 10.156\n",
      "[1,  1000] loss: 7.158 \t test accuracy: 10.156\n",
      "[2,   100] loss: 7.159 \t test accuracy: 10.156\n",
      "[2,   200] loss: 7.171 \t test accuracy: 10.156\n",
      "[2,   300] loss: 7.159 \t test accuracy: 10.156\n",
      "[2,   400] loss: 7.168 \t test accuracy: 10.156\n",
      "[2,   500] loss: 7.153 \t test accuracy: 10.156\n",
      "[2,   600] loss: 7.162 \t test accuracy: 10.156\n",
      "[2,   700] loss: 7.157 \t test accuracy: 10.156\n",
      "[2,   800] loss: 7.155 \t test accuracy: 10.156\n",
      "[2,   900] loss: 7.165 \t test accuracy: 10.156\n",
      "[2,  1000] loss: 7.134 \t test accuracy: 10.156\n",
      "[3,   100] loss: 7.158 \t test accuracy: 10.156\n",
      "[3,   200] loss: 7.155 \t test accuracy: 10.156\n",
      "[3,   300] loss: 7.157 \t test accuracy: 10.156\n",
      "[3,   400] loss: 7.151 \t test accuracy: 10.156\n",
      "[3,   500] loss: 7.156 \t test accuracy: 10.156\n",
      "[3,   600] loss: 7.137 \t test accuracy: 10.156\n",
      "[3,   700] loss: 7.153 \t test accuracy: 10.156\n",
      "[3,   800] loss: 7.153 \t test accuracy: 10.156\n",
      "[3,   900] loss: 7.151 \t test accuracy: 10.156\n",
      "[3,  1000] loss: 7.159 \t test accuracy: 10.156\n",
      "[4,   100] loss: 7.151 \t test accuracy: 10.156\n",
      "[4,   200] loss: 7.153 \t test accuracy: 10.156\n",
      "[4,   300] loss: 7.144 \t test accuracy: 10.156\n",
      "[4,   400] loss: 7.152 \t test accuracy: 10.156\n",
      "[4,   500] loss: 7.137 \t test accuracy: 10.156\n",
      "[4,   600] loss: 7.148 \t test accuracy: 10.156\n",
      "[4,   700] loss: 7.159 \t test accuracy: 10.156\n",
      "[4,   800] loss: 7.149 \t test accuracy: 10.156\n",
      "[4,   900] loss: 7.147 \t test accuracy: 10.156\n",
      "[4,  1000] loss: 7.138 \t test accuracy: 10.156\n",
      "[5,   100] loss: 7.127 \t test accuracy: 10.156\n",
      "[5,   200] loss: 7.128 \t test accuracy: 10.156\n",
      "[5,   300] loss: 7.150 \t test accuracy: 10.156\n",
      "[5,   400] loss: 7.139 \t test accuracy: 10.156\n",
      "[5,   500] loss: 7.117 \t test accuracy: 10.156\n",
      "[5,   600] loss: 7.153 \t test accuracy: 10.156\n",
      "[5,   700] loss: 7.142 \t test accuracy: 10.156\n",
      "[5,   800] loss: 7.139 \t test accuracy: 10.156\n",
      "[5,   900] loss: 7.134 \t test accuracy: 10.156\n",
      "[5,  1000] loss: 7.127 \t test accuracy: 10.156\n",
      "[6,   100] loss: 7.132 \t test accuracy: 10.156\n",
      "[6,   200] loss: 7.128 \t test accuracy: 10.156\n",
      "[6,   300] loss: 7.122 \t test accuracy: 10.156\n",
      "[6,   400] loss: 7.141 \t test accuracy: 10.156\n",
      "[6,   500] loss: 7.118 \t test accuracy: 10.156\n",
      "[6,   600] loss: 7.108 \t test accuracy: 10.156\n",
      "[6,   700] loss: 7.104 \t test accuracy: 10.156\n",
      "[6,   800] loss: 7.118 \t test accuracy: 10.156\n",
      "[6,   900] loss: 7.101 \t test accuracy: 10.156\n",
      "[6,  1000] loss: 7.107 \t test accuracy: 10.156\n",
      "[7,   100] loss: 7.098 \t test accuracy: 10.156\n",
      "[7,   200] loss: 7.119 \t test accuracy: 10.156\n",
      "[7,   300] loss: 7.080 \t test accuracy: 10.156\n",
      "[7,   400] loss: 7.053 \t test accuracy: 10.156\n",
      "[7,   500] loss: 7.114 \t test accuracy: 10.156\n",
      "[7,   600] loss: 7.114 \t test accuracy: 10.156\n",
      "[7,   700] loss: 7.047 \t test accuracy: 10.156\n",
      "[7,   800] loss: 7.069 \t test accuracy: 10.156\n",
      "[7,   900] loss: 7.084 \t test accuracy: 10.156\n",
      "[7,  1000] loss: 7.051 \t test accuracy: 10.156\n",
      "[8,   100] loss: 7.001 \t test accuracy: 10.156\n",
      "[8,   200] loss: 7.034 \t test accuracy: 10.156\n",
      "[8,   300] loss: 7.059 \t test accuracy: 10.156\n",
      "[8,   400] loss: 7.038 \t test accuracy: 10.156\n",
      "[8,   500] loss: 7.015 \t test accuracy: 10.156\n",
      "[8,   600] loss: 6.970 \t test accuracy: 10.156\n",
      "[8,   700] loss: 6.944 \t test accuracy: 10.156\n",
      "[8,   800] loss: 7.029 \t test accuracy: 10.156\n",
      "[8,   900] loss: 6.942 \t test accuracy: 10.156\n",
      "[8,  1000] loss: 6.998 \t test accuracy: 10.156\n",
      "[9,   100] loss: 6.940 \t test accuracy: 10.156\n",
      "[9,   200] loss: 6.945 \t test accuracy: 10.156\n",
      "[9,   300] loss: 6.877 \t test accuracy: 10.156\n",
      "[9,   400] loss: 6.897 \t test accuracy: 10.156\n",
      "[9,   500] loss: 6.817 \t test accuracy: 10.156\n",
      "[9,   600] loss: 6.829 \t test accuracy: 10.156\n",
      "[9,   700] loss: 6.896 \t test accuracy: 10.156\n",
      "[9,   800] loss: 6.898 \t test accuracy: 10.156\n",
      "[9,   900] loss: 6.812 \t test accuracy: 10.156\n",
      "[9,  1000] loss: 6.805 \t test accuracy: 10.156\n",
      "[10,   100] loss: 6.693 \t test accuracy: 10.156\n",
      "[10,   200] loss: 6.690 \t test accuracy: 10.156\n",
      "[10,   300] loss: 6.712 \t test accuracy: 10.156\n",
      "[10,   400] loss: 6.729 \t test accuracy: 10.156\n",
      "[10,   500] loss: 6.639 \t test accuracy: 10.156\n",
      "[10,   600] loss: 6.676 \t test accuracy: 10.156\n",
      "[10,   700] loss: 6.477 \t test accuracy: 10.156\n",
      "[10,   800] loss: 6.530 \t test accuracy: 10.156\n",
      "[10,   900] loss: 6.466 \t test accuracy: 10.156\n",
      "[10,  1000] loss: 6.332 \t test accuracy: 10.156\n",
      "[11,   100] loss: 6.500 \t test accuracy: 10.156\n",
      "[11,   200] loss: 6.346 \t test accuracy: 10.156\n",
      "[11,   300] loss: 6.434 \t test accuracy: 10.156\n",
      "[11,   400] loss: 6.326 \t test accuracy: 10.156\n",
      "[11,   500] loss: 6.336 \t test accuracy: 10.156\n",
      "[11,   600] loss: 6.151 \t test accuracy: 10.156\n",
      "[11,   700] loss: 6.335 \t test accuracy: 10.156\n",
      "[11,   800] loss: 6.318 \t test accuracy: 10.156\n",
      "[11,   900] loss: 6.263 \t test accuracy: 10.156\n",
      "[11,  1000] loss: 6.088 \t test accuracy: 10.156\n",
      "[12,   100] loss: 6.242 \t test accuracy: 10.156\n",
      "[12,   200] loss: 6.034 \t test accuracy: 10.156\n",
      "[12,   300] loss: 6.232 \t test accuracy: 10.156\n",
      "[12,   400] loss: 5.991 \t test accuracy: 10.156\n",
      "[12,   500] loss: 6.086 \t test accuracy: 10.156\n",
      "[12,   600] loss: 5.953 \t test accuracy: 10.156\n",
      "[12,   700] loss: 5.898 \t test accuracy: 10.156\n",
      "[12,   800] loss: 5.980 \t test accuracy: 10.156\n",
      "[12,   900] loss: 5.787 \t test accuracy: 10.156\n",
      "[12,  1000] loss: 6.039 \t test accuracy: 10.156\n",
      "[13,   100] loss: 5.907 \t test accuracy: 10.156\n",
      "[13,   200] loss: 5.989 \t test accuracy: 10.156\n",
      "[13,   300] loss: 5.941 \t test accuracy: 10.156\n",
      "[13,   400] loss: 5.581 \t test accuracy: 10.156\n",
      "[13,   500] loss: 5.738 \t test accuracy: 10.156\n",
      "[13,   600] loss: 5.576 \t test accuracy: 10.156\n",
      "[13,   700] loss: 5.811 \t test accuracy: 10.156\n",
      "[13,   800] loss: 5.834 \t test accuracy: 10.156\n",
      "[13,   900] loss: 5.776 \t test accuracy: 10.156\n",
      "[13,  1000] loss: 5.666 \t test accuracy: 10.156\n",
      "[14,   100] loss: 5.459 \t test accuracy: 10.156\n",
      "[14,   200] loss: 5.647 \t test accuracy: 10.156\n",
      "[14,   300] loss: 5.456 \t test accuracy: 10.156\n",
      "[14,   400] loss: 5.614 \t test accuracy: 10.156\n",
      "[14,   500] loss: 5.705 \t test accuracy: 10.156\n",
      "[14,   600] loss: 5.358 \t test accuracy: 10.156\n",
      "[14,   700] loss: 5.408 \t test accuracy: 10.156\n",
      "[14,   800] loss: 5.717 \t test accuracy: 10.156\n",
      "[14,   900] loss: 5.546 \t test accuracy: 10.156\n",
      "[14,  1000] loss: 5.358 \t test accuracy: 10.156\n",
      "[15,   100] loss: 5.499 \t test accuracy: 10.156\n",
      "[15,   200] loss: 5.413 \t test accuracy: 10.156\n",
      "[15,   300] loss: 5.380 \t test accuracy: 10.156\n",
      "[15,   400] loss: 5.145 \t test accuracy: 10.156\n",
      "[15,   500] loss: 5.634 \t test accuracy: 10.156\n",
      "[15,   600] loss: 5.098 \t test accuracy: 10.156\n",
      "[15,   700] loss: 5.326 \t test accuracy: 10.156\n",
      "[15,   800] loss: 5.226 \t test accuracy: 10.156\n",
      "[15,   900] loss: 5.200 \t test accuracy: 10.156\n",
      "[15,  1000] loss: 5.601 \t test accuracy: 10.156\n",
      "[16,   100] loss: 5.166 \t test accuracy: 10.156\n",
      "[16,   200] loss: 5.430 \t test accuracy: 10.156\n",
      "[16,   300] loss: 5.343 \t test accuracy: 10.156\n",
      "[16,   400] loss: 5.118 \t test accuracy: 10.156\n",
      "[16,   500] loss: 5.221 \t test accuracy: 10.156\n",
      "[16,   600] loss: 5.667 \t test accuracy: 10.156\n",
      "[16,   700] loss: 5.295 \t test accuracy: 10.156\n",
      "[16,   800] loss: 5.201 \t test accuracy: 10.156\n",
      "[16,   900] loss: 5.428 \t test accuracy: 10.156\n",
      "[16,  1000] loss: 5.221 \t test accuracy: 10.156\n",
      "[17,   100] loss: 5.142 \t test accuracy: 10.156\n",
      "[17,   200] loss: 5.158 \t test accuracy: 10.156\n",
      "[17,   300] loss: 5.227 \t test accuracy: 10.156\n",
      "[17,   400] loss: 5.163 \t test accuracy: 10.156\n",
      "[17,   500] loss: 5.308 \t test accuracy: 10.156\n",
      "[17,   600] loss: 5.119 \t test accuracy: 10.156\n",
      "[17,   700] loss: 4.993 \t test accuracy: 10.156\n",
      "[17,   800] loss: 5.149 \t test accuracy: 10.156\n",
      "[17,   900] loss: 5.125 \t test accuracy: 10.156\n",
      "[17,  1000] loss: 5.204 \t test accuracy: 10.156\n",
      "[18,   100] loss: 5.053 \t test accuracy: 10.156\n",
      "[18,   200] loss: 4.987 \t test accuracy: 10.156\n",
      "[18,   300] loss: 4.959 \t test accuracy: 10.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,   400] loss: 4.945 \t test accuracy: 10.156\n",
      "[18,   500] loss: 5.006 \t test accuracy: 10.156\n",
      "[18,   600] loss: 5.082 \t test accuracy: 10.156\n",
      "[18,   700] loss: 5.012 \t test accuracy: 10.156\n",
      "[18,   800] loss: 4.883 \t test accuracy: 10.156\n",
      "[18,  1000] loss: 4.847 \t test accuracy: 10.156\n",
      "[19,   100] loss: 4.870 \t test accuracy: 10.156\n",
      "[19,   200] loss: 5.289 \t test accuracy: 10.156\n",
      "[19,   300] loss: 4.764 \t test accuracy: 10.156\n",
      "[19,   400] loss: 4.790 \t test accuracy: 10.156\n",
      "[19,   500] loss: 4.672 \t test accuracy: 10.156\n",
      "[19,   600] loss: 5.069 \t test accuracy: 10.156\n",
      "[19,   700] loss: 4.873 \t test accuracy: 10.156\n",
      "[19,   800] loss: 4.966 \t test accuracy: 10.156\n",
      "[19,   900] loss: 4.543 \t test accuracy: 10.156\n",
      "[19,  1000] loss: 5.015 \t test accuracy: 10.156\n",
      "[20,   100] loss: 5.043 \t test accuracy: 10.156\n",
      "[20,   200] loss: 4.781 \t test accuracy: 10.156\n",
      "[20,   300] loss: 4.947 \t test accuracy: 10.156\n",
      "[20,   400] loss: 5.016 \t test accuracy: 10.156\n",
      "[20,   500] loss: 4.848 \t test accuracy: 10.156\n",
      "[20,   600] loss: 4.899 \t test accuracy: 10.156\n",
      "[20,   700] loss: 4.993 \t test accuracy: 10.156\n",
      "[20,   800] loss: 4.452 \t test accuracy: 10.156\n",
      "[20,   900] loss: 5.015 \t test accuracy: 10.156\n",
      "[20,  1000] loss: 5.300 \t test accuracy: 10.156\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training with MSE/Quadratic loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "log_interval = 100\n",
    "step = 0\n",
    "# loop over the dataset multiple times\n",
    "for epoch in range(20):  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels, _ = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.to(device))        \n",
    "        loss = criterion(outputs.to(device), labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % log_interval == 0:    # print every 2000 mini-batches\n",
    "            acc_g, acc_v, acc_c, overall = get_accuracy(testloader, net, batch=True)\n",
    "            step_loss = running_loss / (log_interval+1)\n",
    "            tb_writer.add_scalar(\"loss\", loss, step)\n",
    "            tb_writer.add_scalar(\"epoch_loss\", running_loss, step)\n",
    "            \n",
    "            tb_writer.add_scalar(\"grapheme-root-accuracy\", acc_g, step)\n",
    "            tb_writer.add_scalar(\"vowel-diatric-accuracy\", acc_v, step)\n",
    "            tb_writer.add_scalar(\"consonant_diatric-accuracy\", acc_c, step)\n",
    "            tb_writer.add_scalar(\"accuracy\", overall, step)\n",
    "\n",
    "\n",
    "            print('[%d, %5d] loss: %.3f \\t test accuracy: %.3f' % (epoch + 1, i + 1, loss, test_acc))\n",
    "            \n",
    "        step += 1 \n",
    "                        \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(testloader, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"multilabel_fc2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
