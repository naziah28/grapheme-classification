{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from helper_funcs import * \n",
    "from torchvision.models import *\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "from numpy import linalg as LA\n",
    "\n",
    "import tensorboardX\n",
    "\n",
    "batch_size=128\n",
    "random_state = 42 \n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/tonysun94/pytorch-1-0-1-on-mnist-acc-99-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "tb_writer = tensorboardX.SummaryWriter('storage/resnet-sl-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/label-mappings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(testloader, net, batch=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "            \n",
    "            gt = 0 \n",
    "            vt = 0 \n",
    "            ct = 0 \n",
    "            \n",
    "            if batch: \n",
    "                overall = 100 * correct / total\n",
    "                \n",
    "                for (pred, label) in zip(predicted, labels):                    \n",
    "                    l = label.item()\n",
    "                    p = pred.item()\n",
    "                    g, v, c = df[df.label == l].grapheme_root.values[0], \\\n",
    "                        df[df.label == l].vowel_diacritic.values[0], \\\n",
    "                        df[df.label == l].consonant_diacritic.values[0]\n",
    "                    \n",
    "                    pg, pv, pc = df[df.label == p].grapheme_root.values[0], \\\n",
    "                        df[df.label == p].vowel_diacritic.values[0], \\\n",
    "                        df[df.label == p].consonant_diacritic.values[0]   \n",
    "                    \n",
    "                    if g == pg: \n",
    "                        gt += 1 \n",
    "                    if v == pv: \n",
    "                        vt += 1\n",
    "                    if c == pc: \n",
    "                        ct+=1 \n",
    "                g_acc = 100*gt/batch_size\n",
    "                v_acc = 100*vt/batch_size\n",
    "                c_acc = 100*ct/batch_size\n",
    "                overall = (g_acc*2 + v_acc + c_acc) /4 \n",
    "                \n",
    "                return g_acc, v_acc, c_acc, overall\n",
    "                \n",
    "    overall = 100 * correct / total\n",
    "    \n",
    "    return overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_errors(testloader, net, n=10):\n",
    "    count = 0\n",
    "    ims = []\n",
    "    preds = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)            \n",
    "            \n",
    "            for (im, pred, label) in zip(images, predicted, labels):\n",
    "                if pred.numpy() != label.numpy():\n",
    "                    count += 1\n",
    "                    ims.append(im.numpy())\n",
    "                    preds.append(pred)\n",
    "                    actual.append(label)\n",
    "                    \n",
    "                if count >= n: \n",
    "                    return ims, preds, actual \n",
    "                \n",
    "    plot_gallery2(ims, preds, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = BengaliDataset(\"data/train.csv\",\"data/trainsplit\", transform)\n",
    "testset = BengaliDataset(\"data/test.csv\",\"data/testsplit\", transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "classes = list(range(df.label.max()+1))\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels,t = next(iter(trainloader))\n",
    "# images, labels,t = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "plot_gallery2(images,labels,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck\n",
    "\n",
    "\n",
    "class MNISTResNet(ResNet):\n",
    "    def __init__(self):\n",
    "        super(MNISTResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=n_classes) # Based on ResNet18\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3,bias=False)\n",
    "\n",
    "model = MNISTResNet()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target, _) in enumerate(train_loader):\n",
    "        # if GPU available, move data and target to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        # compute output and loss\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # TODO:\n",
    "        # 1. add batch metric (acc1, acc5)\n",
    "        # 2. add average metric top1=sum(acc1)/batch_idx, top5 = sum(acc5)/batch_idx\n",
    "        \n",
    "        # backward and update model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 100 == 0:\n",
    "            step = (epoch*100) + batch_idx \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.data.item()))\n",
    "            \n",
    "    acc_g, acc_v, acc_c, overall = get_accuracy(testloader, model, batch=True)\n",
    "    tb_writer.add_scalar(\"loss\", loss, step)\n",
    "\n",
    "    tb_writer.add_scalar(\"grapheme-root-accuracy\", acc_g, step)\n",
    "    tb_writer.add_scalar(\"vowel-diatric-accuracy\", acc_v, step)\n",
    "    tb_writer.add_scalar(\"consonant_diatric-accuracy\", acc_c, step)\n",
    "    tb_writer.add_scalar(\"accuracy\", overall, step)\n",
    "\n",
    "\n",
    "    print('[%d, %5d] loss: %.3f \\t test accuracy: %.3f' % (epoch + 1, step, loss, overall))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for _, (data, target, _) in enumerate(val_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += criterion(output, target).data.item()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(val_loader.dataset)\n",
    "        \n",
    "    print('\\nOn Val set Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(val_loader.dataset),\n",
    "        100.0 * float(correct) / len(val_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example config, use the comments to get higher accuracy\n",
    "total_epoches = 20 # 50\n",
    "step_size = 5     # 10\n",
    "base_lr = 0.01    # 0.01\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [12800/134562 (10%)]\tLoss: 7.171162\n",
      "Train Epoch: 0 [25600/134562 (19%)]\tLoss: 7.123380\n"
     ]
    }
   ],
   "source": [
    "track_loss = []\n",
    "track_accuracy = []\n",
    "for epoch in range(total_epoches):\n",
    "    train(train_loader=trainloader, model=model, criterion=criterion, optimizer=optimizer, epoch=epoch)\n",
    "    validate(val_loader=testloader, model=model, criterion=criterion)\n",
    "    exp_lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample,labels,_ = next(iter(testloader))\n",
    "output = model(sample.to(device))\n",
    "pred = output.data.max(1, keepdim=True)[1].cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 13, 13\n",
    "\n",
    "# plt.figure(figsize=(12,12))\n",
    "cn_matrix = confusion_matrix(\n",
    "    y_true=labels.numpy(),\n",
    "    y_pred=pred,\n",
    "    labels=list(range(1293)),\n",
    "    normalize=\"true\",\n",
    ")\n",
    "ConfusionMatrixDisplay(cn_matrix, list(range(1293))).plot(\n",
    "    include_values=False, xticks_rotation=\"vertical\"\n",
    ")\n",
    "plt.title(\"Colors\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
