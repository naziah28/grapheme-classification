{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from helper_funcs import * \n",
    "from torchvision.models import *\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "from numpy import linalg as LA\n",
    "\n",
    "batch_size=128\n",
    "random_state = 42 \n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/tonysun94/pytorch-1-0-1-on-mnist-acc-99-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(testloader, net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_accuracies(net):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels.to(device)).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_errors(testloader, net, n=10):\n",
    "    count = 0\n",
    "    ims = []\n",
    "    preds = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)            \n",
    "            \n",
    "            for (im, pred, label) in zip(images, predicted, labels):\n",
    "                if pred.numpy() != label.numpy():\n",
    "                    count += 1\n",
    "                    ims.append(im.numpy())\n",
    "                    preds.append(pred)\n",
    "                    actual.append(label)\n",
    "                    \n",
    "                if count >= n: \n",
    "                    return ims, preds, actual \n",
    "                \n",
    "    plot_gallery2(ims, preds, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = BengaliDataset(\"data/train.csv\",\"data/trainsplit\", transform)\n",
    "testset = BengaliDataset(\"data/test.csv\",\"data/testsplit\", transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "classes = list(range(df.label.max()+1))\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels,t = next(iter(trainloader))\n",
    "# images, labels,t = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "plot_gallery2(images,labels,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck\n",
    "\n",
    "\n",
    "class MNISTResNet(ResNet):\n",
    "    def __init__(self):\n",
    "        super(MNISTResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=n_classes) # Based on ResNet18\n",
    "        # super(MNISTResNet, self).__init__(BasicBlock, [3, 4, 6, 3], num_classes=10) # Based on ResNet34\n",
    "        # super(MNISTResNet, self).__init__(Bottleneck, [3, 4, 6, 3], num_classes=10) # Based on ResNet50\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3,bias=False)\n",
    "\n",
    "model = MNISTResNet()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target, _) in enumerate(train_loader):\n",
    "        # if GPU available, move data and target to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        # compute output and loss\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # TODO:\n",
    "        # 1. add batch metric (acc1, acc5)\n",
    "        # 2. add average metric top1=sum(acc1)/batch_idx, top5 = sum(acc5)/batch_idx\n",
    "        \n",
    "        # backward and update model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for _, (data, target, _) in enumerate(val_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += criterion(output, target).data.item()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(val_loader.dataset)\n",
    "        \n",
    "    print('\\nOn Val set Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(val_loader.dataset),\n",
    "        100.0 * float(correct) / len(val_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example config, use the comments to get higher accuracy\n",
    "total_epoches = 20 # 50\n",
    "step_size = 5     # 10\n",
    "base_lr = 0.01    # 0.01\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [12800/134562 (10%)]\tLoss: 7.160809\n",
      "Train Epoch: 0 [25600/134562 (19%)]\tLoss: 7.124442\n",
      "Train Epoch: 0 [38400/134562 (29%)]\tLoss: 7.104523\n",
      "Train Epoch: 0 [51200/134562 (38%)]\tLoss: 6.534368\n",
      "Train Epoch: 0 [64000/134562 (48%)]\tLoss: 5.878928\n",
      "Train Epoch: 0 [76800/134562 (57%)]\tLoss: 5.044273\n",
      "Train Epoch: 0 [89600/134562 (67%)]\tLoss: 4.610102\n",
      "Train Epoch: 0 [102400/134562 (76%)]\tLoss: 4.164382\n",
      "Train Epoch: 0 [115200/134562 (86%)]\tLoss: 3.647674\n",
      "Train Epoch: 0 [128000/134562 (95%)]\tLoss: 3.074728\n",
      "\n",
      "On Val set Average loss: 0.0235, Accuracy: 16640/66278 (25.106%)\n",
      "\n",
      "Train Epoch: 1 [12800/134562 (10%)]\tLoss: 2.495641\n",
      "Train Epoch: 1 [25600/134562 (19%)]\tLoss: 2.446294\n",
      "Train Epoch: 1 [38400/134562 (29%)]\tLoss: 2.355180\n",
      "Train Epoch: 1 [51200/134562 (38%)]\tLoss: 1.778749\n",
      "Train Epoch: 1 [64000/134562 (48%)]\tLoss: 1.888546\n"
     ]
    }
   ],
   "source": [
    "track_loss = []\n",
    "track_accuracy = []\n",
    "for epoch in range(total_epoches):\n",
    "    train(train_loader=trainloader, model=model, criterion=criterion, optimizer=optimizer, epoch=epoch)\n",
    "    validate(val_loader=testloader, model=model, criterion=criterion)\n",
    "    exp_lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
